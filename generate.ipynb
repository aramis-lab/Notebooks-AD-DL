{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell if running in Google Colab\n",
    "# !pip install clinicadl==0.2.1\n",
    "# !curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/dataOasis.tar.gz -o dataOasis.tar.gz\n",
    "# !tar xf dataOasis.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug architecture search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous sections were focusing on pre-built architectures available in ClinicaDL. These architectures were trained and validated on ADNI, and gave similar test results on ADNI, AIBL and OASIS. However, they might not be transferrable to other problems on other datasets using other modalities, and this is why may want to search for new architectures and hyperparameters.\n",
    "\n",
    "Looking for a new set of hyperparameters often means taking a lot of time training networks that are not converging. To avoid this pitfall, it is often advise to simplify the problem: focus on a subset of data / classification task that is more tractable than the one that is currently explored. This is the purpose of `clinicadl generate` which creates a set of synthetic, tractable data from real data to check that developed networks are working on this simple case before going further.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tractable data:</b><p>\n",
    "    In this notebook, we call tractable data a set of pairs of images and labels that can be easily classified. In ClinicaDL, tractable data is generated from real brain images and consist in creating two classes in which the intensitites of the left or the right part of the brain are decreased.</p>\n",
    "    <img src=\"images/generate.png\" style=\"height: 200px;\" alt=\"Schemes of synthetic tractable data\">\n",
    "</div>\n",
    "\n",
    "If you ran the previous notebook, you must have a folder called `OasisCaps_example` in the current directory (Otherwise uncomment the next cell to download a local version of the necessary folders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/OasisCaps2.tar.gz -o OasisCaps2.tar.gz\n",
    "# !tar xf OasisCaps2.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tractable data\n",
    "\n",
    "Tractable data can be generated from real data with the following command line\n",
    "\n",
    "```Text\n",
    "clinicadl generate trivial <caps_directory> <output_directory> --n_subjects <n_subjects>\n",
    "```\n",
    "where:\n",
    "\n",
    "- `caps_directory` is the output folder containing the results in a [CAPS](http://www.clinica.run/doc/CAPS/) hierarchy.\n",
    "- `output_directory` is the folder where the synthetic CAPS is stored.\n",
    "- `n_subjects` is the number of subjects per label in the synthetic dataset. Default value: 300.\n",
    "\n",
    "```{warning}\n",
    "`n_subjects` cannot be higher than the number of subjects in the initial dataset. Indeed in each synthetic class, a synthetic image derives from a real image.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!clinicadl generate trivial OasisCaps_example t1-linear data/synthetic --n_subjects 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command will generate synthetic data in nifti files. To train the network, tensor files must be extracted with `clinicadl extract`. For more information on the following command line, please read the section [Prepare your neuroimaging data](./preprocessing.ipynb).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Image-level classification:</b><p>\n",
    "    This notebook will only focus on image-level classification. It is also possible to perform patch-level, slice-level and region-based classification. For more information read the corresponding section <a href=\"./training.ipynb\">Train your own models</a>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!clinica run deeplearning-prepare-data data/synthetic t1-linear image --n_procs 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce the tsv file system necessary to train\n",
    "\n",
    "In order to train a network, meta data must be organized in a file system generated by `clinicadl tsvtool`. For more information on the following commands, please read the section [Define your population](./label_extraction.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the labels AD and CN in separate files\n",
    "!clinicadl tsvtool getlabels data/synthetic/data.tsv data/synthetic/missing_mods data/synthetic/labels_list --modality synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "!clinicadl tsvtool split data/synthetic/labels_list --n_test 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation data in a 5-fold cross-validation\n",
    "!clinicadl tsvtool kfold data/synthetic/labels_list/train --n_splits 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model on synthetic data\n",
    "\n",
    "Once data was generated and split it is possible to train a model using `clinicadl train` and evaluate its performance with `clinicadl classify`. For more information on the following command lines please read the sections [Train your own models](./training.ipynb) and [Perfom classification using pretrained models](./inference.ipynb).\n",
    "\n",
    "The following command uses a pre-build architecture of ClinicaDL `Conv4_FC3`. You can also implement your own models by following the instructions of [this section](./training.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train a network with synthetic data\n",
    "!clinicadl train roi cnn data/synthetic t1-linear data/synthetic/labels_list/train results/synthetic Conv4_FC3 --n_splits 3 --split 0 -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of images is very small (4 per class), we do not rely on the accuracy to select the model. Instead we evaluate the model which obtained the best loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the network performance on the 2 test images\n",
    "!clinicadl classify ./data/synthetic ./data/synthetic/labels_list/test ./results/synthetic 'test' --selection_metrics \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-TRIV4</td>\n",
       "      <td>ses-M00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-TRIV5</td>\n",
       "      <td>ses-M00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id session_id  true_label  predicted_label\n",
       "0      sub-TRIV4    ses-M00           1                1\n",
       "1      sub-TRIV5    ses-M00           0                0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>ppv</th>\n",
       "      <th>npv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  balanced_accuracy  sensitivity  specificity  ppv  npv\n",
       "0       1.0                1.0          1.0          1.0  1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fold = 0\n",
    "\n",
    "predictions = pd.read_csv(\"./results/synthetic/fold-%i/cnn_classification/best_loss/test_image_level_prediction.tsv\" % fold, sep=\"\\t\")\n",
    "display(predictions)\n",
    "\n",
    "\n",
    "metrics = pd.read_csv(\"./results/synthetic/fold-%i/cnn_classification/best_loss/test_image_level_metrics.tsv\" % fold, sep=\"\\t\")\n",
    "display(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}