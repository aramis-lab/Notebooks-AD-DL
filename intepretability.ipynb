{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell if running in Google Colab\n",
    "# !pip install clinicadl==0.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate saliency maps on trained networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining black-box models can be useful to better understand their behaviour. For more information on this complex topic, we highly recommend the review of [Xie et al.](http://arxiv.org/abs/2004.14545).\n",
    "\n",
    "In ClinicaDL, the most basic method of interpretability was implemented: [gradients visualization](https://arxiv.org/pdf/1312.6034.pdf) (sometimes called saliency maps).\n",
    "\n",
    "This method can be performed on an individual or on a group fashion (in this case it will be the mean value of all the individual saliency maps in the group)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we are going to extract saliency maps from a model already trained on ADNI. If you did not run the notebook on classification, you will need to uncomment the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading pretrained model\n",
    "# !curl -k https://aramislab.paris.inria.fr/files/data/models/dl/models_v002/model_exp3_splits_1.tar.gz  -o model_exp3_splits_1.tar.gz\n",
    "# !tar xf model_exp3_splits_1.tar.gz\n",
    "\n",
    "# Downloading Oasis CAPS\n",
    "# !curl -k https://aramislab.paris.inria.fr/files/data/databases/tuto/OasisCaps2.tar.gz -o OasisCaps2.tar.gz\n",
    "# !tar xf OasisCaps2.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate individual saliency maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saliency maps on corresponding to one image can be computed with the following command:\n",
    "```bash\n",
    "clinicadl interpret individual <model_path> <name>\n",
    "```\n",
    "where:\n",
    "- `model_path` is the path to the pretrained model folder,\n",
    "- `name` is the name of the interpretability job.\n",
    "\n",
    "Default will try to load the data used for training (which is not possible here). Then you will need to set the following options:\n",
    "- `--tsv_path`, the path the TSV file with all the subjects and sessions to use,\n",
    "- `--caps_dir`, the path to the CAPS in which the images defined in `tsv_path` are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!clinicadl interpret group \"model_exp8_splits_1\" \"group\" --tsv_path \"OasisCaps_example/participants.tsv\" -np 0 --caps_dir \"OasisCaps_example\" -cpu --target_diagnosis \"CN\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
