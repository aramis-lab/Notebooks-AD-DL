{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Classification (Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<SCRIPT SRC='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></SCRIPT>\n",
    "<SCRIPT>MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]}})</SCRIPT> \n",
    "\n",
    "This notebook shows how to perform classification on preprocessed data using pretrained models of [Wen et al, 2020](https://www.sciencedirect.com/science/article/abs/pii/S1361841520300591).\n",
    "\n",
    "## Structure of the pretrained models\n",
    "\n",
    "All the pretrained model folders are organized as follows:\n",
    "<pre>\n",
    "<b>results</b>\n",
    "├── commandline.json\n",
    "├── <b>fold-0</b>\n",
    "├── ...\n",
    "└── <b>fold-4</b>\n",
    "    ├── <b>models</b>\n",
    "    │      └── <b>best_balanced_accuracy</b>\n",
    "    │          └── model_best.pth.tar\n",
    "    └── <b>cnn_classification</b>\n",
    "           └── <b>best_balanced_accuracy</b>\n",
    "               └── validation_{patch|roi|slice}_level_prediction.tsv\n",
    "</pre>\n",
    "This file system is a part of the output of `clinicadl train` and `clinicadl classify` relies on three files:\n",
    "<ul>\n",
    "    <li> <code>commandline.json</code> contains all the options that were entered for training (type of input, architecture, preprocessing...)</li>\n",
    "    <li> <code>model_best.pth.tar</code> corresponds to the model selected when the best validation balanced accuracy was obtained.</li>\n",
    "    <li> <code>validation_{patch|roi|slice}_level_prediction.tsv</code> is specific to patch, roi and slice frameworks and is necessary to perform <b>soft-voting</b> thus finding the label on the image level in unbiased way. Indeed weighting the patches based on their performance of input data would bias the result as the classification framework would exploit knowledge on test data.</li>\n",
    "</ul>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Soft voting:</b><p>\n",
    "    For classification tasks which take as input a part of the MRI volume (<i>patch, roi or slice</i>), an ensemble operation is needed to obtain the label at the image level.</p>\n",
    "    <p>For example, size and stride of 50 voxels on linear preprocessing leads to the classification of 36 patches, but they are not all equally meaningful. Patches that are in the corners of the image are mainly composed of background and skull and may be misleading, whereas patches in the brain may be more useful.</p>\n",
    "    <img src=\"./images/patches.png\">\n",
    "    <p>Then the image-level probability of AD <i>p<sup>AD</sup></i> will be:</p>\n",
    "    $$ p^{AD} = {\\sum_{i=0}^{35} bacc_i * p_i^{AD}}.$$\n",
    "    where:<ul>\n",
    "    <li> <i>p<sub>i</sub><sup>AD</sup></i> is the probability of AD for patch <i>i</i></li>\n",
    "    <li> <i>bacc<sub>i</sub></i> is the validation balanced accuracy for patch <i>i</i></li>\n",
    "    </ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the pretrained models\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "**Warning:** For the sake of the demostration, this tutoriel uses truncated versions of the models, containing only the first fold.\n",
    "\n",
    "</div>\n",
    "\n",
    "In this notebook, we propose to use 4 specific models , all of them where trained to predict a classification task AD vs CN. (The experiment corresponding to the pretrained model in eTable 4 of the paper mentioned above is shown besides):\n",
    "\n",
    "1. **3D image-level model**, pretrained with the baseline data and initialized with an autoencoder (_cf._ exp. 3).\n",
    "2. **3D roi-based model**, pretrained with the baseline data and initialized with an autoencoder (_cf._ exp. 8).\n",
    "3. **3D patch-level model**, multi-cnn, pretrained with the baseline data and initialized with an autoencoder (_cf._ exp. 14).\n",
    "4. **2D slice-level model**, pretrained with the baseline data and initialized with an autoencoder (_cf._ exp. 18).\n",
    "\n",
    "Commands in the next code cell will automatically download these models and uncompress them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download here the pretrained models stored online\n",
    "# Model 1\n",
    "!curl -k https://aramislab.paris.inria.fr/files/data/models/dl/models_v002/model_exp3_splits_1.tar.gz  -o model_exp3_splits_1.tar.gz\n",
    "!tar xf model_exp3_splits_1.tar.gz\n",
    "\n",
    "# Model 2\n",
    "!curl -k https://aramislab.paris.inria.fr/files/data/models/dl/models_v002/model_exp8_splits_1.tar.gz  -o model_exp8_splits_1.tar.gz\n",
    "!tar xf model_exp8_splits_1.tar.gz\n",
    "\n",
    "# Model 3\n",
    "!curl -k https://aramislab.paris.inria.fr/files/data/models/dl/models_v002/model_exp14_splits_1.tar.gz  -o model_exp14_splits_1.tar.gz\n",
    "!tar xf model_exp14_splits_1.tar.gz\n",
    "\n",
    "# Model 4\n",
    "!curl -k https://aramislab.paris.inria.fr/files/data/models/dl/models_v002/model_exp18_splits_1.tar.gz  -o model_exp18_splits_1.tar.gz\n",
    "!tar xf model_exp18_splits_1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `clinicadl classify`\n",
    "\n",
    "Running classification on a dataset is extremly simple using `clinicadl`. In this case, we will continue using the data preprocessed in the [previous notebook](./preprocessing). The models have been trained exclusively on ADNI dataset, all the subjects of OASIS-1 can be used to evaluate the model (without risking data leackage).\n",
    "\n",
    "If you ran the previous notebook, you must have a folder called `OasisCaps_example` in the current directory. In the following steps we will classify these images using the pretrained models. The input necessary for `clinica classify` are:\n",
    "* A Caps directory (`OasisCaps_example`)\n",
    "* A tsv file with subjects/sessions to process, containing the diagnosis.\n",
    "* The path to the pretrained model.\n",
    "\n",
    "Some optional parameters includes:\n",
    "* An output prefix for the output file, defined by the user (`-pre`)\n",
    "* The posibility of process non labeled data (without diagnosis).\n",
    "* The option to use previously extracted patches/slices.\n",
    "\n",
    "For these examples, we will use the simplest case, by adding a prefix for the output files:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "If your computer is not equiped with a GPU card add the option `-cpu` to the command.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute classify on OASIS dataset\n",
    "# Model 1\n",
    "!clinicadl classify ./OasisCaps_example ./OasisBids_example/OasisParticipants.tsv ./model_exp3_splits_1 -pre 'test_DB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification results for the subjects of this dataset can be displayed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./model_exp3_splits_1/fold-0/cnn_classification/best_balanced_accuracy/test_DB_image_level_prediction.tsv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, we can process the dataset with all the other models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "!clinicadl classify ./OasisCaps_example ./OasisBids_example/OasisParticipants.tsv ./model_exp8_splits_1 -pre 'test_DB'\n",
    "\n",
    "# Model 3\n",
    "!clinicadl classify ./OasisCaps_example ./OasisBids_example/OasisParticipants.tsv ./model_exp14_splits_1 -pre 'test_DB'\n",
    "\n",
    "# Model 4\n",
    "!clinicadl classify ./OasisCaps_example ./OasisBids_example/OasisParticipants.tsv ./model_exp18_splits_1 -pre 'test_DB'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
